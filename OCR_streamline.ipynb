{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8197a938-5fa0-4813-9057-3e979ca6e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "10.8 s ± 565 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56782fe-1904-4049-9470-24b0cf55a14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From c:\\users\\dale\\programming\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n",
      "11.4 s ± 1.29 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import keras_ocr\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf6e32b-4579-4608-ab07-c6a9e395c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3f5931-8c70-435e-9073-8cb76c7a3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBox():\n",
    "    def __init__(self, stupid_box):\n",
    "        self.word = stupid_box[0]\n",
    "        self.top = min([i[1] for i in stupid_box[1]])\n",
    "        self.left = min([i[0] for i in stupid_box[1]])\n",
    "        self.bottom = max([i[1] for i in stupid_box[1]])\n",
    "        self.right = max([i[0] for i in stupid_box[1]])\n",
    "        self.height = self.bottom - self.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c0bff2-f6b8-450d-990e-4a7b1eb9d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigBox():\n",
    "    def __init__(self, list_of_simple_boxes):\n",
    "        self.original = list_of_simple_boxes\n",
    "        self.top = min([i.top for i in list_of_simple_boxes])\n",
    "        self.left = min([i.left for i in list_of_simple_boxes])\n",
    "        self.bottom = max([i.bottom for i in list_of_simple_boxes])\n",
    "        self.right = max([i.right for i in list_of_simple_boxes])\n",
    "        self.height = self.bottom - self.top\n",
    "        self.center = ((self.right - self.left)/2) + self.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599cb536-c076-4145-827c-b799c1c87374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_groups(text_from_image, bottom_of_row_gap=10, next_word_distance=10, next_row_distance=10, margin_closeness=10):\n",
    "    texts = [SimpleBox(text) for text in text_from_image]\n",
    "    # could sort texts by finding min of right bottom point (x + y) or, like, pythagorean theorem\n",
    "    \n",
    "    row_groups = []\n",
    "    while texts:\n",
    "        # grab first word\n",
    "        text = texts[0]\n",
    "        \n",
    "        # collect all text on same \"line\"\n",
    "        temp_row = [j for j in texts if abs(text.bottom - j.bottom) < text.height/2]\n",
    "        \n",
    "       # sort the list in place in order of left to right\n",
    "        temp_row.sort(key=lambda x: x.left, reverse=False)\n",
    "#         print([i.word for i in temp_row])\n",
    "        \n",
    "        # Find large breaks within words\n",
    "        # Initialize new list with first word\n",
    "        temp_row_2 = [temp_row[0]]\n",
    "        # Loop through rest of words in temp_row\n",
    "        for index, word in enumerate(temp_row[1:]):\n",
    "            # Is word close to previous?\n",
    "            if abs(word.left - temp_row[index].right) < text.height/2:\n",
    "                temp_row_2.append(word)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "#         print('final temp_row_2', [word.word for word in temp_row_2])\n",
    "        # add word group to collection\n",
    "        row_groups.append(temp_row_2)\n",
    "        # remove those words from possible words\n",
    "        [texts.pop(texts.index(word)) for word in temp_row_2]\n",
    "    \n",
    "    # Now to check if rows are near each other... somehow...\n",
    "    rows = [BigBox(row) for row in row_groups]\n",
    "    \n",
    "    text_groups = []\n",
    "    while rows:\n",
    "        matching_row = rows[0]\n",
    "        \n",
    "        group = [matching_row]\n",
    "        for new_row in rows[1:]:\n",
    "            # is top of new_row near bottom of our row?\n",
    "            if (new_row.top - matching_row.bottom) < (matching_row.height*.75):\n",
    "                # and is center of row within the margins of our row?\n",
    "                if  matching_row.left < new_row.center < matching_row.right:\n",
    "                    group.append(new_row)\n",
    "                    matching_row = new_row\n",
    "                    \n",
    "        text_groups.append(group)\n",
    "        # remove those rows from possible rows\n",
    "        [rows.pop(rows.index(row)) for row in group]\n",
    "    \n",
    "    return text_groups\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004bbe14-06de-49a9-b8f0-f50fb13ccc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_positional_information(text_groups):\n",
    "    \"\"\"\n",
    "    Takes the result from create_text_groups and returns only the text.\n",
    "    TODO: build this object in the create_text_groups function to prevent\n",
    "    this double loop.\n",
    "    \"\"\"\n",
    "    text = {}\n",
    "    text['groupings'] = [[[word.word for word in line.original] for line in group] for group in text_groups]\n",
    "    text['raw_text'] = '\\n\\n'.join(['\\n'.join([' '.join([word.word for word in line.original]) for line in group]) for group in text_groups])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3fbe078-92a9-4ed7-9f92-b5dde4286d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\dale\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From c:\\users\\dale\\programming\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Looking for C:\\Users\\dale\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867d6103-5c40-4cbc-9a63-e059423e06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_dir = '/Users/dale/Downloads/r7PpXQD4/'\n",
    "filenames = os.listdir(media_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936b3120-a185-45ce-a8a7-1253fbcefb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "image_names = []\n",
    "errors = []\n",
    "for file in filenames:\n",
    "    try:\n",
    "        images.append(keras_ocr.tools.read(media_dir + file))\n",
    "        image_names.append(file)\n",
    "    except Exception as e:\n",
    "        print(e, end='', flush=True)\n",
    "        errors.append((file, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fffb0c43-a599-4d40-a27d-379c7ca45793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e88f5e3-c0b6-4180-a881-5f7333426ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL images\n",
    "to_do = [(image_name, image) for image_name, image in zip(image_names, images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70a07edf-d2c5-4740-a683-60ade70eecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remaining images\n",
    "#...\n",
    "with open('remaining.pkl', 'rb') as remaining_file:\n",
    "    test = pickle.load(remaining_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45ede6e1-f657-4112-973b-26282b045108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "to_do = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acfa856c-a1f0-49ca-ab50-8d0a90d04cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 of 18 completed\r"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "total = len(to_do)\n",
    "\n",
    "with open('reddit_meme_predictions.ndjson', 'a') as results_file:\n",
    "\n",
    "    while to_do:\n",
    "        image_name, image = to_do.pop(0)\n",
    "        num += 1\n",
    "        \n",
    "        try:\n",
    "            prediction = pipeline.recognize([image])\n",
    "            text_groups = remove_positional_information(create_text_groups(prediction[0]))\n",
    "            results_file.write(json.dumps({\n",
    "                                           'name': image_name,\n",
    "                                           'text' : text_groups,\n",
    "                                          }))\n",
    "            results_file.write('\\n')\n",
    "            print(str(num) + ' of ' + str(total) + ' completed', end='\\r', flush=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e, flush=True) \n",
    "            results_file.write(json.dumps({\n",
    "                                           'name': image_name,\n",
    "                                           'error' : str(e),\n",
    "                                          }))\n",
    "            results_file.write('\\n')\n",
    "        \n",
    "        # update remaining (cause this thing takes forever!)\n",
    "        with open('remaining.pkl', 'wb') as remaining_file:\n",
    "            pickle.dump(to_do, remaining_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a4ea11b-c08a-4329-ae47-fba45a8cfbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('reddit_meme_predictions.ndjson', 'r') as results_file:\n",
    "    for line in results_file.readlines():\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9f71e6f-ee4e-47aa-b836-9ad41ada33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0rlo319o4w671.jpg :\n",
      "nobody\n",
      "\n",
      "reddit live streamers\n",
      "_________________________________\n",
      "2scwgdir4w671.jpg :\n",
      "me after eating 2 bags of popcorni 2 filled to the brim bowls of cereal and 3 cadburys oreo chocolate bars wondering why im not losing weight and have diarrhea\n",
      "\n",
      "ting ne think\n",
      "_________________________________\n",
      "58gqpnjk3w671.gif :\n",
      "oi mate we goin to\n",
      "tesco ye wan anything\n",
      "_________________________________\n",
      "6s1o3fn84w671.png :\n",
      "4y0 me after i planted a cashew\n",
      "into sand and its already been 134 seconds\n",
      "\n",
      "let the dark harvest beginuu\n",
      "_________________________________\n",
      "7aax1qe84w671.jpg :\n",
      "cheering for the\n",
      "villain in disney\n",
      "movies\n",
      "\n",
      "cheering for\n",
      "the villain in\n",
      "starwars\n",
      "\n",
      "cheering for\n",
      "the villain in\n",
      "1943 disney\n",
      "shows\n",
      "\n",
      "made with mematic\n",
      "_________________________________\n",
      "9u7nfnmg4w671.jpg :\n",
      "igbtq\n",
      "the moon\n",
      "\n",
      "80957 likes\n",
      "\n",
      "igbtq its official the moon is gay\n",
      "\n",
      "of apansystbattie by ashamelesspinup makeup byn\n",
      "view all 20927 comments\n",
      "september 24 2020\n",
      "\n",
      "more\n",
      "\n",
      "me and\n",
      "the boys\n",
      "_________________________________\n",
      "9g17d9bo3w671.jpg :\n",
      "wikipedia\n",
      "lache sach\n",
      "geschichten\n",
      "\n",
      "co\n",
      "\n",
      "imgflp com\n",
      "\n",
      "levels germany\n",
      "_________________________________\n",
      "9u7nfnmg4w671.jpg :\n",
      "igbtq\n",
      "the moon\n",
      "\n",
      "80957 likes\n",
      "\n",
      "igbtq its official the moon is gay\n",
      "\n",
      "of apansystbattie by ashamelesspinup makeup byn\n",
      "view all 20927 comments\n",
      "september 24 2020\n",
      "\n",
      "more\n",
      "\n",
      "me and\n",
      "the boys\n",
      "_________________________________\n",
      "afsakllf3w671.jpg :\n",
      "my well\n",
      "\n",
      "end of deserved\n",
      "work\n",
      "\n",
      "one customer\n",
      "closing before\n",
      "\n",
      "minute entering\n",
      "_________________________________\n",
      "cqmkk3ar4w671.png :\n",
      "andwe told him\n",
      "\n",
      "imgtp com he s able to upload memes\n",
      "_________________________________\n",
      "final_60d25db99a1653004b18f2b9_904451.gif :\n",
      "when you call her but\n",
      "her name is not maybe\n",
      "\n",
      "darthnawat\n",
      "_________________________________\n",
      "hd4j3h4y3w671.png :\n",
      "teachers when a kid raises\n",
      "his hand to answer the\n",
      "question\n",
      "\n",
      "sleep\n",
      "\n",
      "teachers when the same kid\n",
      "raises his hand to go to the\n",
      "bathroom\n",
      "_________________________________\n",
      "hycj377f3w671.jpg :\n",
      "server walks up to this table\n",
      "and asks\n",
      "ladies is anything okk\n",
      "_________________________________\n",
      "i834naxm4w671.jpg :\n",
      "me as a childs kvisit the doctork\n",
      "doctor as a reward you can choose\n",
      "something from the toy box\n",
      "me trying to find the coolest toy\n",
      "\n",
      "ulasktrashmeme\n",
      "_________________________________\n",
      "jt94vvpj4w671.jpg :\n",
      "redditers remembering a\n",
      "repostothis meme was\n",
      "originally posted in 69 bc\n",
      "\n",
      "redditers\n",
      "remembering\n",
      "answers in exam\n",
      "_________________________________\n",
      "kq1zhq6q4w671.jpg :\n",
      "this generation of people is really\n",
      "troublesome\n",
      "\n",
      "cnn\n",
      "\n",
      "acnn 11h\n",
      "cnnj jamaican track and field great usain bolt\n",
      "announced the birth of his twin sons in an\n",
      "instagram post on fatherl s day this sunday\n",
      "\n",
      "cnn com\n",
      "\n",
      "sle ek\n",
      "mal\n",
      "\n",
      "usain bolt and partner kasi bennett\n",
      "welcome newborn twin sons thunder and a\n",
      "\n",
      "8284\n",
      "\n",
      "me\n",
      "\n",
      "sean parsons liberalday 11h\n",
      "usain has no right to proclaim that the twins are\n",
      "isons m itls really disgusting to see cnn\n",
      "endorsing this act of predetermining gender\n",
      "made with mematicnd reinforcing stereotypes\n",
      "_________________________________\n",
      "plixbflo3w671.jpg :\n",
      "bootyhole getting\n",
      "annihillated\n",
      "\n",
      "five guys\n",
      "\n",
      "five guys\n",
      "\n",
      "made with mematic\n",
      "_________________________________\n",
      "skzysvk64w671.png :\n",
      "me and the boys after we get that we\n",
      "\n",
      "a\n",
      "\n",
      "wo\n",
      "_________________________________\n",
      "t8pntqpc3w671.jpg :\n",
      "you dont\n",
      "haye to bl\n",
      "perfect to\n",
      "be\n",
      "successful\n",
      "_________________________________\n",
      "wk71gv2m3w671.jpg :\n",
      "when you were about to go\n",
      "3rd base with\n",
      "then\n",
      "\n",
      "a girly but\n",
      "wakes you upr\n",
      "\n",
      "mom\n",
      "\n",
      "we were on the verge of greatness\n",
      "we were this close\n",
      "_________________________________\n",
      "yx3xwdf04w671.jpg :\n",
      "me after writing an entire\n",
      "paper the day before its due\n",
      "and writing the date as 3 weeks ago\n",
      "\n",
      "imailo con fuck off em a time godl\n",
      "_________________________________\n",
      "z70613wd4w671.jpg :\n",
      "my oldest brother\n",
      "whos graduating university\n",
      "and getting a job as an\n",
      "engineer\n",
      "\n",
      "me who wants\n",
      "to be a writer\n",
      "\n",
      "my other brother\n",
      "who is\n",
      "\n",
      "to\n",
      "\n",
      "going\n",
      "university to\n",
      "study science\n",
      "_________________________________\n",
      "zg2ydkbs4w671.jpg :\n",
      "e\n",
      "\n",
      "mail online\n",
      "\n",
      "news\n",
      "\n",
      "q\n",
      "\n",
      "ikea in atlanta is slammed for\n",
      "offering racially insensitive\n",
      "juneteenth menu featuring fried\n",
      "chicken and watermelon\n",
      "\n",
      "by andrew court for dailymail com\n",
      "2109 22 jun 2021\n",
      "\n",
      "updated 214 22 jun 2021\n",
      "\n",
      "m\n",
      "\n",
      "cin\n",
      "\n",
      "s the\n",
      "lavi\n",
      "\n",
      "kea\n",
      "\n",
      "oto\n",
      "\n",
      "tiic\n",
      "\n",
      "i was a business man\n",
      "\n",
      "doing business\n",
      "_________________________________\n",
      "zkamsdgs4w671.jpg :\n",
      "the devil and angel ldk lm\n",
      "not religious\n",
      "_________________________________\n",
      "zlyx6mqo3w671.jpg :\n",
      "a rust player with an aka7\n",
      "\n",
      "s\n",
      "\n",
      "an innocent homeless\n",
      "newbie who did iterally\n",
      "nothing\n",
      "_________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    if 'text' in i.keys():\n",
    "        print(i['name'], ':')\n",
    "        print(i['text']['raw_text'])\n",
    "        print('_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d11d15af-0312-4e07-a536-5e83f0fb66d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6a2db-aa1b-48dd-837b-851f64d1343c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
